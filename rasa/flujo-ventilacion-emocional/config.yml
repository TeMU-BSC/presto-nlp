# Configuration for Rasa NLU.
# https://rasa.com/docs/rasa/nlu/components/
language: es

pipeline:
  - name: WhitespaceTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 3
    # OOV_token: _oov_
  # - name: LanguageModelFeaturizer
  #   # Name of the language model to use
  #   model_name: "roberta"
  #   # Pre-Trained weights to be loaded
  #   model_weights: "PlanTL-GOB-ES/roberta-base-bne"

  #   # An optional path to a specific directory to download and cache the pre-trained model weights.
  #   # The `default` cache_dir is the same as https://huggingface.co/transformers/serialization.html#cache-directory .
  #   cache_dir: null
  # #  Whether to use a shared vocab
  # #   use_shared_vocab: False


### Custom components and classifiers
  - name: sentiment.SentimentEntityExtractor
  - name: DIETClassifier
    epochs: 15
    constrain_similarities: true 
  - name: EntitySynonymMapper

# Fallback and chitchat components
  - name: FallbackClassifier
    threshold: 0.5

  - name: ResponseSelector  
    epochs: 100
    retrieval_intent: chitchat

policies:
### Transformers dialogue policies:
   - name: TEDPolicy
     epochs: 20
     constrain_similarities: true
   - name: UnexpecTEDIntentPolicy
     tolerance: 0.3
     epochs: 20

### Conversational contextualization --> se ha alterado esta politica para ver si generamos mayor consistencia en el desarrollo de las conversaciones contextuales
   - name: AugmentedMemoizationPolicy
     max_history: 8

### Rule policies
   - name: RulePolicy 
     core_fallback_threshold: 0.3
     core_fallback_action_name: "action_default_fallback"
     enable_fallback_prediction: True

